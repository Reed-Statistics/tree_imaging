<!--
This is for including Chapter 1.  Notice that it's also good practice to name your chunk.  This will help you debug potential issues as you knit.  The chunk above is called intro and the one below is called chapter1.  Feel free to change the name of the Rmd file as you wish, but don't forget to change it here from chap1.Rmd.
-->

<!--
The {#rmd-basics} text after the chapter declaration will allow us to link throughout the document back to the beginning of Chapter 1.  These labels will automatically be generated (if not specified) by changing the spaces to hyphens and capital letters to lowercase.  Look for the reference to this label at the beginning of Chapter 2.
-->

```{r echo=F}
knitr::opts_chunk$set(fig.width=6, fig.height=4, fig.align='center')
```


<!-- # R Markdown Basics {#rmd-basics} -->

<!-- Here is a brief introduction into using _R Markdown_. _Markdown_ is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. _R Markdown_ provides the flexibility of _Markdown_ with the implementation of **R** input and output.  For more details on using _R Markdown_ see <https://rmarkdown.rstudio.com>.   -->

<!-- Be careful with your spacing in _Markdown_ documents.  While whitespace largely is ignored, it does at times give _Markdown_ signals as to how to proceed.  As a habit, try to keep everything left aligned whenever possible, especially as you type a new paragraph.  In other words, there is no need to indent basic text in the Rmd document (in fact, it might cause your text to do funny things if you do). -->

<!-- ## Lists -->

<!-- It's easy to create a list.  It can be unordered like -->

<!-- * Item 1 -->
<!-- * Item 2 -->

<!-- or it can be ordered like -->

<!-- 1. Item 1 -->
<!-- 4. Item 2 -->

<!-- Notice that I intentionally mislabeled Item 2 as number 4.  _Markdown_ automatically figures this out!  You can put any numbers in the list and it will create the list.  Check it out below. -->

<!-- To create a sublist, just indent the values a bit (at least four spaces or a tab).  (Here's one case where indentation is key!) -->

<!-- 1. Item 1 -->
<!-- 1. Item 2 -->
<!-- 1. Item 3 -->
<!--     - Item 3a -->
<!--     - Item 3b -->

<!-- ## Line breaks -->

<!-- Make sure to add white space between lines if you'd like to start a new paragraph.  Look at what happens below in the outputted document if you don't: -->

<!-- Here is the first sentence.  Here is another sentence.  Here is the last sentence to end the paragraph. -->
<!-- This should be a new paragraph. -->

<!-- *Now for the correct way:*  -->

<!-- Here is the first sentence.  Here is another sentence.  Here is the last sentence to end the paragraph. -->

<!-- This should be a new paragraph. -->

<!-- ## R chunks -->

<!-- When you click the **Knit** button above a document will be generated that includes both content as well as the output of any embedded **R** code chunks within the document. You can embed an **R** code chunk like this (`cars` is a built-in **R** dataset): -->

<!-- ```{r cars} -->
<!-- summary(cars) -->
<!-- ``` -->

<!-- ## Inline code -->

<!-- If you'd like to put the results of your analysis directly into your discussion, add inline code like this: -->

<!-- > The `cos` of $2 \pi$ is `r cos(2*pi)`.  -->

<!-- Another example would be the direct calculation of the standard deviation: -->

<!-- > The standard deviation of `speed` in `cars` is `r sd(cars$speed)`. -->

<!-- One last neat feature is the use of the `ifelse` conditional statement which can be used to output text depending on the result of an **R** calculation: -->

<!-- > `r ifelse(sd(cars$speed) < 6, "The standard deviation is less than 6.", "The standard deviation is equal to or greater than 6.")` -->

<!-- Note the use of `>` here, which signifies a quotation environment that will be indented. -->

<!-- As you see with `$2 \pi$` above, mathematics can be added by surrounding the mathematical text with dollar signs.  More examples of this are in [Mathematics and Science] if you uncomment the code in [Math].   -->

<!-- ## Including plots -->

<!-- You can also embed plots. For example, here is a way to use the base **R** graphics package to produce a plot using the built-in `pressure` dataset: -->

<!-- ```{r pressure, echo=FALSE, cache=TRUE, fig.height=3, fig.width=5} -->
<!-- plot(pressure) -->
<!-- ``` -->

<!-- Note that the `echo=FALSE` parameter was added to the code chunk to prevent printing of the **R** code that generated the plot. There are plenty of other ways to add chunk options (like `fig.height` and `fig.width` in the chunk above).  More information is available at <https://yihui.org/knitr/options/>.   -->

<!-- Another useful chunk option is the setting of `cache=TRUE` as you see here.  If document rendering becomes time consuming due to long computations or plots that are expensive to generate you can use knitr caching to improve performance.  Later in this file, you'll see a way to reference plots created in **R** or external figures. -->

<!-- ## Loading and exploring data -->

<!-- Included in this template is a file called `flights.csv`.  This file includes a subset of the larger dataset of information about all flights that departed from Seattle and Portland in 2014. More information about this dataset and its **R** package is available at <https://github.com/ismayc/pnwflights14>. This subset includes only Portland flights and only rows that were complete with no missing values. Merges were also done with the `airports` and `airlines` data sets in the `pnwflights14` package to get more descriptive airport and airline names. -->

<!-- We can load in this data set using the following commands: -->

<!-- ```{r load_data} -->
<!-- # flights.csv is in the data directory -->
<!-- # string columns will be read in as strings and not factors now -->
<!-- flights <- read.csv('~/tree_imaging/index/data/flights.csv', stringsAsFactors = FALSE) -->
<!-- ``` -->

<!-- The data is now stored in the data frame called `flights` in **R**.  To get a better feel for the variables included in this dataset we can use a variety of functions. Here we can see the dimensions (rows by columns) and also the names of the columns. -->

<!-- ```{r str} -->
<!-- dim(flights) -->
<!-- names(flights) -->
<!-- ``` -->

<!-- Another good idea is to take a look at the dataset in table form.  With this dataset having more than 20,000 rows, we won't explicitly show the results of the command here. I recommend you enter the command into the Console **_after_** you have run the **R** chunks above to load the data into **R**. -->

<!-- ```{r view_flights, eval=FALSE} -->
<!-- View(flights) -->
<!-- ``` -->

<!-- While not required, it is highly recommended you use the `dplyr` package to manipulate and summarize your data set as needed.  It uses a syntax that is easy to understand using chaining operations.  Below I've created a few examples of using `dplyr` to get information about the Portland flights in 2014.  You will also see the use of the `ggplot2` package, which produces beautiful, high-quality academic visuals. -->

<!-- We begin by checking to ensure that needed packages are installed and then we load them into our current working environment: -->

```{r load_pkgs, message=FALSE, warning=F, echo=F}
# List of packages required for this analysis
pkg <- c("dplyr", "ggplot2", "knitr", "bookdown")
# Check if packages are not installed and assign the
# names of the packages not installed to the variable new.pkg
new.pkg <- pkg[!(pkg %in% installed.packages())]
# If there are any packages in the list that aren't installed,
# install them
if (length(new.pkg)) {
  install.packages(new.pkg, repos = "https://cran.rstudio.com")
}
# Load packages
library(thesisdown)
library(tidyverse)
library(ggplot2)
library(knitr)
library(pdxTrees)
library(kableExtra)
```

\clearpage

## Research Problem and Background
Western redcedar trees are evergreen trees that typically grow up to 75 feet tall and are located over the Pacific Northwest, making it an organism with a tolerance for shaded regions with moist environments. These trees are native to the land and have served many purposes to people and animals living in the vicinity of the trees, including medicinal, building, and habitat functions [@peterson_western_nodate]. However, over the past decade, reports of dead western redcedars have been increasing, suggesting that something other than natural causes is killing off this species. In general, this species experiences several hardships in surviving in the Pacific Northwest, with common causes of death such as forest fires, clearcutting, small animals eating the saplings, and harsh weather including strong winds that easily uproot the trees [@peterson_western_nodate]. Dying redcedar trees can be identified by their branches which turn brownish yellow or fall off completely. Another sign is that the top of a dying redcedar will turn brown and lose leaves [@noauthor_western_nodate]. Losing this native tree would have a detrimental effect on animals in the area who rely heavily on the trees for their lifestyle. Scientists have speculated that western redcedar decline might be caused by recent dry summers, the spread of tree disease, insects, or other weather related events [@noauthor_western_nodate]. Since this is a recent issue, there is not a lot of resources explaining the decline. This research aims to provide more insight into the cause of the western redcedar decline by first predicting the location of the western redcedar trees in Portland and then predicting their condition in terms of health. Having more insight helps to prevent further tree deaths and save the western redcedar species, which also extends to similar tree species and provides more knowledge about environmental changes in the Pacific Northwest region.

Modelling in this research will be conducted by combining information gathered from remote sensing images with ground level information. There are several sources publishing research done using satellite imagery for land classification and for predicting tree species, which will be the groundwork for this project's application of remote sensing models to the specific topic of western redcedar mortality. 

Plenty of literature has been published in utilizing satellite imagery for predictive models, however, many issues arise in classifying land type through remote sensing mainly due to image quality. A single image can be composed of image strips taken over the course of multiple flight paths. Consequently, these images are taken at different times of day, which compiles into a single image with a lot of variation in values due to changes in the weather as well as the different angles of the sun's position [@castelluccio_land_2015]. Ideally, a solid classifying model surpasses any error introduced by imperfection in the satellite images. Common approaches to classification on satellite images include support vector machines, random forests, and decision trees. One study on land type classification explores the performance of convolutional neural networks (CNN) as classification models [@castelluccio_land_2015].

Another related study identifies 7 tree species by applying a hyperspectral CNN model. This study was completed using field data with measured information about tree count, tree species, and mortality status and hyperspectral imagery data. The hyperspectral data is converted into the form of a tree canopy height model with circular polygons centered at individual tree canopies. The study analyzes the performance of CNNs for both hyperspectral imagery data and a Red-Green-Blue (RGB) subset of the hyperspectral imagery data. The results of the experiment conclude that training a CNN on the hyperspectral data outperforms the CNN trained on RGB data in classifying land type on the UC Merced Land Use dataset. The RGB model does not perform as well as the hyperspectral model in terms of distinguishing tree classes, but does perform around the same level of accuracy in terms of genus classification. For this project, the data comes from Planet.com and only has RGB data available for the Portland region.

This thesis follows along with the methods in [@fricker_convolutional_2019] for combining the satellite imagery data with ground data by creating spatial polygons and extracting pixel-level information to train classification models. The work in this thesis differs from the methods in the cited literature by using random forests and support vector machines as classification models instead of CNNs and uses the RGB model instead of hyperspectral model. Finally, this thesis applies established classification methods for satellite imagery data to answer the specific question about the cause of death of western redcedars in the Pacific Northwest. First models predicted the locations for each tree species, then the health conditions of the western redcedars are modelled to identify any patterns in the species mortality over the past decade.

## Overview
### A Statistical Learning Approach to Identifying Location of Western Redcedars
This work combines RGB imagery data from Planet.com with ground level tree data from the RStudio `pdxTrees` library and applies random forest and support vector machine classification methods to predict the location of tree species (specifically western redcedars) in Portland, Oregon and model the condition of western redcedars to ultimately understand the cause of death in this species. [insert key findings here]

## Data Chapter

There are two sources of data in this project. Data at a pixel level come from satellite images downloaded from Planet.com (https://www.planet.com), and data at the ground level come from library `pdxTrees` in RStudio (https://github.com/mcconvil/pdxTrees). 

### Imaging

Satellite images come from Planet.com's PS2.SD instrument found on Dove-R satellites that were launched in 2017. The PS2 telescope is equipped with a 2D frame detector with 6600 pixels across by 4400 pixels down and a spacing of 1100 pixels. One pixel = 5.5um. To separate the light into red, blue, green, and non-infrared (NIR) channels, the telescope has a high-performance butcher-block filter made of 4 individual pass-band filters. Planet.com equates this pass-band filter with that of Sentinel-2.

As it orbits the Earth, the satellite captures continuous strips of single frame images that are split into a RGB frame and NIR frame. Images are are downloaded already fully processed and ready to be analyzed. The process includes corrections for radiometric calibration, terrain distortions corrections, elevation corrections, and atmospheric corrections.

The images used in this research were taken on September 2nd, 2020 at an altitude of 475 km. The compiled multi-spectral image is composed of 4 bands: blue, green, red, and near-infrared (NIR), with center wavelengths 490 nm, 565 nm, 665 nm, and 865 nm respectively, with an average bandwidth of 41 nm. The average spatial extent is around 25 km by 8 km. The images cover the entire Portland area, with specific measurements of 26 km from west to east and 30 km from north to south. The spatial resolution of the pixels is approximately 3 meters.

Using Planet.com for gathering satellite images has the added benefit of providing a limited number of downloadable images by making a free account. However, one drawback to using this data is that its low resolution, which will decrease the performance of statistical models trying to predict tree species location.

### Ground Data
Ground level data is available from the ‘pdxTrees’ package in RStudio. This data was collected as part of the Portland’s Parks and Recreation’s Urban Forestry Tree Inventory Project, which collected park tree information from 2017 to 2019. Originally, the inventory project started with the goal of improving the city's tree management plans. Under the guidance of US Forestry staff, volunteers around the city's neighborhoods are trained in identifying tree species and provided with tools necessary to record tree measurements. Measurements in feet were made using diameter tape. The Portland park trees inventory consists of over 25,000 trees, each with information about tree location, size, species, and health. For the purposes of this project, the following variables were selected:

* Spatial information: Longitude and latitude of tree. Location of tree is recorded on a tablet with Collector for ArcGIS and recorders manually select the tree from a satellite image on the screen.

* Species: Tree genus, species, and common name


* Crown size: Crown width from north to south, crown width from east to west, and the base height of the crown in feet. The crown of the tree is the tree's above ground leaves, so the crown width is the longest horizontal distance that can be measured between the leaves of the tree. A measuring wheel is used to measure this distance.

* Tree Condition: Categorical variable with four categories (from best to worst), good, fair, poor, and dead. A tree was considered good if the tree is strong and has no apparent issues, fair if the tree is average condition with possibly a few dead branches, poor if the tree has major wounds and dead major canopy loss, and dead if the tree has no live leaves.


To prepare the ground level data for training the model, the data was filtered by species and crown size. The following tree species were identified and included: maples, oak, Douglas-fir, Western Redcedar, and sequoia. Since the data is used to identify trees in the satellite images, the ground data was also filtered to only include the trees with a crown width from north to south of 20 feet or more, this ensures that there will be around 9 to 20 pixels per tree.

Portland's Tree Inventory provides valuable data for this project because it includes a variable for identifying Western Redcedars as well as variables for identifying larger trees in the dataset, which helps construct a training set of tree polygons in a satellite image. One way this data would be even better suited for the purposes of this project would be if the street trees subdata also contained variables for tree canopy size.

### Training Data

#### Characteristics of Training Data

The training data at the ground-level was filtered by tree size and tree type. Trees with at least 20 feet in north to south crown width were included in the training dataset to ensure that the polygons around each tree contain around 9 to 20 pixels. Figure \@ref(fig:crownWidth) plots the north to south crown width values against the west to east crown width values to present the ranges of crown widths in the entire pdxTrees parks dataset and to justify only using the north to south crown width for filtering the dataset since the two variables have a strong positive correlation.


```{r crownWidth, warning=F, message=F, echo=F, fig.cap='Plot comparing North to South Crown Width (ft) to West to East Crown Width (ft). A tree with a higher north-south crown width has a higher west-east crown width, so without loss of generality the north-south crown width variable is used to filter the dataset for larger trees only.'}
pdxTrees_parks <- get_pdxTrees_parks()
ggplot(pdxTrees_parks, aes(x = Crown_Width_NS, y = Crown_Width_EW)) +
  geom_point(alpha = 0.4) +
  theme_classic() + labs(x = "North to South Crown Width (ft)", y = "West to East Crown Width (ft)")
```


Six tree types were determined to have large enough canopies on average and appear frequently enough to construct a training dataset with plenty of observations for each species of tree: Douglas-Fir, English Oak, Giant Sequoia, Maple, Western Redcedar. Table \@ref(tab:pointsTable) provides the number of trees under each common name category. The largest group contains 6485 observations of Douglas-Fir trees, and the smallest group contains 135 observations of English Oak trees.


```{r pointsTable, warning=F, message=F, echo=F, fig.cap='Common tree names included in the tidy data and their total counts.'}
train_points <- pdxTrees_parks %>%
  dplyr::filter(Species %in% c("QURO", "SEGI", "ACPL", "PSME", "ACMA", "THPL"), Crown_Width_NS >= 20)

train_points_dat <- train_points %>%
  group_by(Common_Name) %>%
  summarise(counts = n()) %>%
  arrange(desc(counts))

knitr::kable(train_points_dat, col.names = c("Tree Name", "Tree Count"), "latex", caption = "Common tree names included in the tidy data and their total counts.")
```

#### Creating Spatial Polygons

The training dataset was converted into shapefiles for each type of tree and exported into QGIS where polygons were manually drawn around 100 of the trees for each species. The point shapefile layers were displayed over the raster images downloaded from Planet.com in QGIS, which provided a guide point for locating individual trees. Then using QGIS's drawing tool, a polygon is carefully drawn around the tree canopy. Most polygons turned out to be four to six-sided polygons to retain the general shape of the tree canopy. Trees polygons were only created if the outline of the tree canopy was clearly visible or surrounded by other trees of the same species in order to avoid including pixels from the wrong species in that polygon. Also, the shadows of the trees are visible in the raster images, so the polygons were drawn with the intention of not including the tree shadow. For the five different species of trees, at least 100 polygons were drawn around trees of that type, with each polygon containing at least 6 pixels and at most 20 pixels. The polygon shapefiles were then exported into RStudio where the rest of the analysis was conducted.

#### Combining Ground-level Data with Pixel-level Data

The first spatial join in RStudio was conducted to match up each Spatial Polygon with a point in the training dataset. Then the raster images were loaded and joined with the polygons to extract the pixel values inside each polygon for all 4 bands (red, green, blue, infrared). Ultimately this turned into a pixel table with rows representing each pixel with its corresponding polygon, light reflection intensity values for all 4 bands, and the ground information about that tree. Table \@ref(tab:pixelHead) displays the first few entries of the pixels dataset. Table \@ref(tab:pixelCounts) contains the summary of the total number of pixels for each tree type.

```{r pixelHead, echo=F, warning=F, message=F, fig.cap='Variables and pixel values included in the pixels dataset', fig.width=4}
# load data
pixels_data <- read.csv('~/tree_imaging/pixels_data.csv')
pixels_head <- head(pixels_data)

knitr::kable(pixels_head, caption = "Variables and pixel values included in the pixels dataset") %>%
  kable_styling(latex_options = c("scale_down"))
```


```{r pixelCounts, echo=F, warning=F, message=F, fig.cap='Number of pixels per tree type'}
pixels_summary_dat <- pixels_data %>%
  group_by(Cmmn_Nm) %>%
  summarise(counts = n())

knitr::kable(pixels_summary_dat, col.names = c("Tree Name", "Pixels Count"), "latex", caption = "Number of pixels per tree type")
```

Figure \@ref(fig:pixDensity) displays the range of reflection intensity pixel values per tree type. Each tree species has similar ranges of values over the red, green, blue, and infared bands. Of the species included in the training data, the Giant Sequoia trees appear to have higher density counts for the red, green, and blue bands.

```{r pixDensity, echo=F, warning=F, message=F, fig.cap=' '}
ggplot(pixels_data) +
  geom_density(aes(x = red), col = "red") +
  geom_density(aes(x = blue), col = "blue") + 
  geom_density(aes(x = green), col = "green") + 
  geom_density(aes(x = ir), col = "purple") + 
  facet_wrap(~Cmmn_Nm)+
  theme_classic() + labs(x = "Reflection Intensity", y = "Density")
```

