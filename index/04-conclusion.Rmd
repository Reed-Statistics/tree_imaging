# Results {#results}

## Training Results

Predicting on the grouped data produced the highest overall accuracies. The best model on the grouped data was the RF training model with an mtry value of 3 predictors at each split and the following predictors: red, green, blue, infrared, NDVI, $\frac{\mbox{red}}{\mbox{green}}$, $\frac{\mbox{red}}{\mbox{blue}}$. This model had a training predictive accuracy of 0.57 overall and 0.35 for Western redcedars specifically. On the test dataset, this model accurately predicted 65% of the pixels, while the accuracy for predicting more than half the pixels correctly in the same polygon was 51%. 

The model that performed best among SVM models was the radial SVM on 5 class data. This model had a training accuracy of 0.44 overall, 0.33 for just Western redcedars, and testing accuracy of 0.59 overall and 0.45 for Western redcedar pixels. For polygon predictions, the radial SVM C = 5 model had an accuracy of 54%. These models are used to proceed with the final model over Portland.

## Modelling Tree Species in Portland

After masking the raster images of the entire region of Portland, the pre-trained models are used to predict the tree species of individual pixels in the masked raster images. The `predict.raster` function from RStudio's `raster` package takes a model and applies that model to each cell of the raster, leaving a raster with tree classification predictions. This function is used to predict tree species over all five raster strips, and the raster strips are merged to display predictions for the entire city. Figure \@ref(fig:rfPortland) displays the tree classification predictions given by the optimal random forest model over Portland and figure \@ref(fig:rfPortlandGroup) displays the predictions from the support vector machine model.

```{r rfPortland, results="asis", echo=FALSE, fig.cap="Model tree classification predictions of Western Redcedars over entire Portland region using the random forest model with 8 predictors on 7 classes.", out.width='100%', fig.align='center'}
include_graphics("figure/rfPortland.png")
```

```{r rfPortlandGroup, results="asis", echo=FALSE, fig.cap="Model tree classification predictions of Western Redcedars over entire Portland region using RF model with 7 predictors on 5 classes.", out.width='100%', fig.align='center'}
include_graphics("figure/rfPortlandGroup.png")
```

In comparing the RF C = 5 model results to the RF P = 7, C = 5 results, 83% of the pixel predictions were the same predictions under both models.

To assess the performance of the model over the Portland region, the results are compared to the remaining Western redcedars from `pdxTrees` both street and park data. The shapefiles for `pdxTrees` Western redcedars ground data are mapped over the classified pixel predictions, and the number of correctly and incorrectly classified pixels is recorded to be 52% accurate for RF C = 7 and 66% for RF C = 7. Figure \@ref(fig:resultsToStreet) visualizes this comparison.

```{r resultsToStreet, results="asis", echo=FALSE, fig.cap="Comparison of Wester redcedar RF pixel predictions (in green) to Western redcedar trees from pdxTrees (in blue).", out.width='100%', fig.align='center'}
include_graphics("figure/resultsToStreet.png")
```

# Discussion {#discussion}

## Polygon Pixel Extraction Versus Point Pixel Extraction
Following along with the Fricker Methods [@fricker_convolutional_2019], a training dataset is constructed with multiple pixels from a single tree (extracted from the polygon shape). Another dataset was included in the methods of this research constructed with single pixels representing individual trees to investigate how the methods compare. Especially with low-resolution imagery, this analysis questions whether several pixels representing one tree in training a model is more beneficial than having a single pixel representing one tree (where that pixel is the center location of the tree's canopy). The most comparable Western Redcedar prediction accuracy among the point pixel models was the radial SVM C = 5 model, which was 0.29 compared to the radial SVM C = 5 model on pixel data with 0.33 Western Redcedar accuracy. The other point pixel models performed worse in overall validation accuracy, suggesting that polygon pixel extraction provides more information to train the model with more accuracy.

## RF Performance Versus SVM Performance
The 7 predictor RF model predicting 5 classes outperforms the SVM model predicting 5 classes in Western redcedar training accuracy and testing overall accuracy as well as testing prediction of Western Redcedars. Surprisingly, the testing accuracies were higher than the validation accuracies for both the RF and SVM models. This suggests that the training set was not representative of the true data or the model was underfitting the data. The SVM model performs significantly worse than the RF model in Western Redcedar predictions on the test data. One explanation might be that the validation Western Redcedar accuracy aggregates the results of all 10 cross-validation sets, which might inflate the values, but the test results only consists of one set. Another explanation could be that the lower testing accuracy is an idication of model overfitting, however, the overall testing accuracy is higher than the overall training accuracy. In general, having a small number of predictors compared to the number of classes tends to perform poorly. It was also observed that the models predicting less classes (Broadleaf, Douglas-Fir, Giant Sequoia, Grass, and Western Redcedar) outperformed models predicting on a larger set of tree classes (Bigleaf Maple, English Oak, Norway Maple, Douglas-Fir, Giant Sequoia, Grass, and Western Redcedar). This is likely a result of only having 4-band imagery plus the variables that are linear combinations of these 4 bands; 8 predictors training a model to predict 7 classes will not predict as well as 8 predictors training a model to predict 5 classes. In comparing the entire RF results on Portland to the `pdxTrees`, the test accuracy was 0.65.

## Model Results Compared to Fricker Methods [@fricker_convolutional_2019]
Fricker's methods are conducted under ideal circumstances. The single image strip used in the study had a spatial resolution of 1 meter, they had access to both hyperspectral imagery and RGB imagery, and the ground data was carefully collected to consist of seven tree species [@fricker_convolutional_2019]. Fricker's results show that models using hyperspectral images performed better than RGB image models because they provide additional information by including spectral band combinations not available from RGB images. For this research, the images only consist of 4 bands (red, green, blue, and infrared), are accessible online, and have a spatial resolution of 3 meters. Fricker's methods applying a convolution neural network using hyperspectral imagery produced cross-validation training accuracies of 87%. On just RGB imagery, this accuracy dropped to 64%, which is slightly less than the best performing model (RF P = 8, C = 5) from this research which had a cross-validation training accuracy of 65%.

## Methods of Improvement/Further Work
As Fricker's article has shown, increasing the spectral resolution by having access to hyperspectral data adds more information to the models and improves performance. Hyperspectral imagery collects information from more regions of the spectrum than RGB imagery, which allows it to capture finer details. Tree and vegetation pixels reflect a certain amount of light, especially regions of dense forests, so having more bands can allow the models to detect subtle differences in vegetation pixels with non-vegetation pixels. By increasing the number of variables in the model, the risk of multicollinearity that comes from artificially creating predictors with linear combinations of the RGB bands also gets removed. The benefits of high spatial and spectral resolution imagery also extends to improving the masks applied to the images, which were successful, for example, in removing building structures and dead fields of grass, but incorrectly recognized mossy lakes as trees. Carefully masking the images improves the ability of the model to locate tree pixels and classify them.

In terms of data, another improvement to this research would be to increase the spatial resolution to 1 meter or better if possible. This refines the process of creating polygons by enhancing the visibility of the tree canopy outlines and reduces noise introduced by having shadows, dirt, building structures, and other non-tree pixels within the polygons. Another method to improve the results is by improving the drawn polygons themselves to only include pixels that represent the tree canopy. Drawing the polygons for each tree species by hand is likely to introduce error to the analysis because the first few polygons are not likely to be drawn the same way that the last few polygons are drawn. This issue is addressed by taking care to only include pure tree pixels (no shadows, dirt, or other structures) and ensuring that each polygon consists of at least 10 pixels.

An ideal training data set for the models would consist of data from imagery with high spatial and spectral resolution and also polygons with pure tree canopy pixels. If multiple raster strips are neccessary for the area of interest, the polygons need to be evenly distributed across all raster strips and ideally the tree species per polygon as well. The trees themselves should have large canopies that hopefully do not overlap with other tree canopies of different species.

With these improvements, the research will allow researchers to have a better understanding of the locations of redcedars in Portland. From there, this information provides a way to track future changes in redcedar trees's health, and inform decisions about tree management in the city. In a broader context, applying this method to Portland imagery data with multiple strips provides information about the applicability of modelling tree locations in different parts of the world and with data from different satellites. Ultimately, tracking the changes of the ecosystem allows people to take steps to preserve dying species.

## Conclusion

Reports of Western redcedars in the Pacific Northwest over the past 10 years have sparked an interest in investigating the decline of the species. This research combined RGB imagery and ground-level data available for the city of Portland to try and predict the locations of Western redcedars and progress towards understanding the decline of the species and eventually expand the methods to larger regions like the Pacific Northwest. Ground-level data was used to locate individual tree canopies and label their species on the satellite images, then the light intensities were extracted for each tree canopy pixel into a training data set. Random forest and support vector machine models were trained to classify 7 or 5 tree species. The best performing model was the random forest model with 7 predictors on 5 tree species with an F-score of 0.5 for Western redcedars. These results were not as high as other results from data with better conditions (higher spatial and spectral resolutions), however, they provide a better way of classifying a tree pixel as Western redcedar than a random guess of one of the 7 species (probability of $1/7 \approx 0.14$).

The results of this research are replicable, since it involves data from open sources and the coding is completed in RStudio, and not too computationally intensive to require more than a day to run all of the code. Another key takeaway is that this research applies the methods of using remote sensing imagery to classify tree species in Portland specifically and provides a guideline for general areas to focus on locating Western redcedars. The research is another application of remote sensing for tree species classification, which has the potential to predict more tree species in larger regions with more research.

<!-- If we don't want Conclusion to have a chapter number next to it, we can add the `{-}` attribute. -->

<!-- **More info** -->

<!-- And here's some other random info: the first paragraph after a chapter title or section head _shouldn't be_ indented, because indents are to tell the reader that you're starting a new paragraph. Since that's obvious after a chapter or section title, proper typesetting doesn't add an indent there. -->

