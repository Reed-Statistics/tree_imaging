---
title: "models_svm_randomforest"
author: "Sarah"
date: "11/8/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggspatial)
library(maptools)
library(tigris)
library(caret)
library(corrplot)
library(gridExtra)
```

```{r}
# load data
pixels_data <- read.csv('data/pixels_data.csv')

# adding different ratio predictors, removing grass
pixels_data <- pixels_data %>%
  mutate(red_blue = red/blue,
         ir_red = ir/red,
         red_green = red/green,
         blue_green = blue/green)

# group by number of polygons per tree class per strip
poly_count <- pixels_data %>%
  group_by("Raster Strip" = rstrip, "Tree Name" = Cmmn_Nm) %>%
  count("Polygons" = length(unique(ID)))

# split into 70% train, 30% test, stratified on tree classes per raster strip

# training data
set.seed(2)
train <- pixels_data %>%
  group_by(rstrip, Cmmn_Nm) %>%
  slice_sample(prop = 0.7) %>% # takes 70% from each 
  ungroup() %>%
  group_by(Cmmn_Nm) %>%
  slice_sample(n = 500) %>% # selects n pixels from each class in each raster
  dplyr::select(red, green, blue, ir, ndvi, Cmmn_Nm, red_blue, ir_red, red_green, blue_green)

# test data
test_full <- anti_join(pixels_data, train)
test <- test_full %>%
  dplyr::select(red, green, blue, ir, ndvi, Cmmn_Nm, red_blue, ir_red, red_green, blue_green)

# grouped data to reduce class prediction size (douglas fir, sequoia, redcedar, broadleaf)
test_full_grouped <- test_full %>%
  mutate(Cmmn_Nm = case_when(
      Cmmn_Nm %in% c("Bigleaf Maple", "English Oak", "Norway Maple") ~ "Broadleaf",
      TRUE ~ as.character(Cmmn_Nm)
    ))

train_grouped <- train %>%
  mutate(Cmmn_Nm = case_when(
    Cmmn_Nm %in% c("Bigleaf Maple", "English Oak", "Norway Maple") ~ "Broadleaf",
    TRUE ~ as.character(Cmmn_Nm)
  ))

test_grouped <- test %>%
  mutate(Cmmn_Nm = case_when(
    Cmmn_Nm %in% c("Bigleaf Maple", "English Oak", "Norway Maple") ~ "Broadleaf",
    TRUE ~ as.character(Cmmn_Nm)
  ))
```

```{r}
# preprocess pca
train_pca <- preProcess(dplyr::select(train, -Cmmn_Nm), method = c("center", "scale", "pca"))
train_pca
train_pca$method
train_pca$rotation
```

```{r}
# look at correlation matrix to select predictors
corr_matrix <- round(cor(train %>% ungroup() %>% dplyr::select(-Cmmn_Nm)), 2)
corrplot(corr_matrix, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

# train1 <- train %>%
#   dplyr::select(red, green, blue, ir, ndvi, Cmmn_Nm)
train2 <- train %>%
  dplyr::select(red, green, blue, ir, ndvi, red_green, blue_green, Cmmn_Nm)
train2_grouped <- train_grouped %>%
  dplyr::select(red, green, blue, ir, ndvi, red_green, blue_green, Cmmn_Nm)
train3 <- train %>%
  dplyr::select(red, green, blue, ir, ndvi, red_green, red_blue, blue_green, Cmmn_Nm)
train3_grouped <- train_grouped %>%
  dplyr::select(red, green, blue, ir, ndvi, red_green, red_blue, blue_green, Cmmn_Nm)
```

```{r}
# random search random forest using caret package
control <- trainControl(method = "repeatedcv", number = 10, 
                        search = "random")
set.seed(2)
# rf_random1 <- train(Cmmn_Nm~., data = train1, method = "rf", trControl = control)
rf_random2 <- train(Cmmn_Nm~., data = train2, method = "rf", trControl = control)
rf_random3 <- train(Cmmn_Nm~., data = train3, method = "rf", trControl = control)

# random forest on grouped data
rf2_grouped <- train(Cmmn_Nm~., data = train2_grouped, method = "rf", 
                     trControl = control)
rf3_grouped <- train(Cmmn_Nm~., data = train3_grouped, method = "rf", 
                     trControl = control)
```

```{r}
# compare rf models

# collect resamples
results <- rbind(cbind(rf_random2$resample, Model = rep("P = 7, C = 7", 10)), 
                 cbind(rf_random3$resample, Model = rep("P = 8, C = 7", 10)),
                 cbind(rf2_grouped$resample, Model = rep("P = 7, C = 5", 10)),
                 cbind(rf3_grouped$resample, Model = rep("P = 8, C = 5", 10)))

# visualize rf model results
ggplot(results, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_boxplot(alpha = 0.6) +
  theme_minimal() + 
  scale_fill_viridis_d() +
  labs(title = "Model Accuracy of Random Forest Models with 10-Fold CV", 
       x = " ", fill = "P = Predictors, C = Classes") + 
  theme(axis.text.x = element_blank())

# rf results by class
cm1 <- confusionMatrix(rf_random2,  mode = "prec_recall")
cm2 <- confusionMatrix(rf_random3,  mode = "prec_recall")
cm3 <- confusionMatrix(rf2_grouped,  mode = "prec_recall")
cm4 <- confusionMatrix(rf3_grouped,  mode = "prec_recall")

# rf mtry cross validation
grid.arrange(plot(rf_random2, main = "RF P = 7, C = 7"),
             plot(rf2_grouped, main = "RF P = 7, C = 5"), nrow = 1)
grid.arrange(plot(rf_random3, main = "RF P = 8, C = 7"),
             plot(rf3_grouped, main = "RF P = 8, C = 5"), nrow = 1)

# save confusion matrices
saveRDS(cm1, "data/cm1.rds")
saveRDS(cm2, "data/cm2.rds")
saveRDS(cm3, "data/cm3.rds")
saveRDS(cm4, "data/cm4.rds")

# view specific results
rf3_grouped[["finalModel"]]
varImp(rf3_grouped)

# table comparing models
results_rf <- rbind(cbind(rf_random2$resample, Model = rep("P = 7, C = 7", 10),
                          mtry = rep(rf_random2$bestTune[1,1], 10)),
                    cbind(rf_random3$resample, Model = rep("P = 8, C = 7", 10),
                          mtry = rep(rf_random3$bestTune[1,1], 10)),
                    cbind(rf2_grouped$resample, Model = rep("P = 7, C = 5", 10),
                          mtry = rep(rf2_grouped$bestTune[1,1], 10)),
                    cbind(rf3_grouped$resample, Model = rep("P = 8, C = 5", 10),
                          mtry = rep(rf3_grouped$bestTune[1,1], 10)))
```


```{r}
# 10 fold cross validation
train_control <- trainControl(method = "cv", number = 10)
set.seed(2)
# fit svm model with normalized variables
svm1 <- train(Cmmn_Nm ~., data = train, method = "svmLinear", trControl = train_control,
              preProcess = c("center","scale"))

# fit nonlinear svm model (radial basis)
svm2 <- train(Cmmn_Nm ~., data = train, method = "svmRadial", trControl = train_control, 
              preProcess = c("center","scale"), tuneLength = 10)

# fit nonlinear svm model (polynomial basis)
svm3 <- train(Cmmn_Nm ~., data = train, method = "svmPoly", trControl = train_control, 
              preProcess = c("center","scale"))

# fit svm models on grouped data
svm4 <- train(Cmmn_Nm ~., data = train_grouped, method = "svmLinear", 
              trControl = train_control,  preProcess = c("center","scale"))
svm5 <- train(Cmmn_Nm ~., data = train_grouped, method = "svmRadial", 
              trControl = train_control, preProcess = c("center","scale"))
svm6 <- train(Cmmn_Nm ~., data = train_grouped, method = "svmPoly", 
              trControl = train_control, preProcess = c("center","scale"))
# models with normalized variables
# svm7 <- train(Cmmn_Nm ~., data = train, method = "svmRadial", 
#               trControl = train_control, preProcess = "range")
# svm8 <- train(Cmmn_Nm ~., data = train, method = "svmPoly", 
#               trControl = train_control, preProcess = "range")
```

```{r}
# compare svm models

# collect resamples
results_svm <- rbind(cbind(svm1$resample, Model = rep("Linear, C = 7", 10, 10),
                           Parameter = paste("C =", svm1$bestTune[1,1])),
                     cbind(svm2$resample, Model = rep("Radial, C = 7", 10, 10),
                           Parameter = paste("C =", svm2$bestTune[1,2], "sigma =", 
                                 round(svm2$bestTune[1,1], 4))),
                     cbind(svm3$resample, Model = rep("Poly, C = 7", 10, 10),
                           Parameter = paste("C =", svm3$bestTune[1,3], ", scale =", 
                                 svm3$bestTune[1,2], ", degree =", svm3$bestTune[1,1])),
                     cbind(svm4$resample, Model = rep("Linear, C = 5", 10, 10),
                           Parameter = paste("C =", svm4$bestTune[1,1])),
                     cbind(svm5$resample, Model = rep("Radial, C = 5", 10, 10),
                           Parameter = paste("C =", svm5$bestTune[1,2], "sigma =",
                                             round(svm5$bestTune[1,1], 4))),
                     cbind(svm6$resample, Model = rep("Poly, C = 5", 10, 10),
                           Parameter = paste("C =", svm6$bestTune[1,3], ", scale =", 
                                 svm6$bestTune[1,2], ", degree =", svm6$bestTune[1,1])))

# visualize svm model results
ggplot(results_svm, aes(x = Model, y = Accuracy, fill = Model)) +
  geom_boxplot(alpha = 0.6) +
  theme_minimal() + 
  scale_fill_viridis_d() +
  labs(title = "Model Accuracy of SVM Models with 10-Fold CV", x = " ", fill = " ") + 
  theme(axis.text.x = element_blank())

grid.arrange(plot(svm2, main = "SVM C = 7"),
             plot(svm5, main = "SVM C = 5"), nrow = 1)
grid.arrange(plot(svm3, main = "SVM C = 7"),
             plot(svm6, main = "SVM C = 5"), nrow = 1)

# svm results by class
scm1 <- confusionMatrix(svm1,  mode = "prec_recall")
scm2 <- confusionMatrix(svm2,  mode = "prec_recall")
scm3 <- confusionMatrix(svm3,  mode = "prec_recall")
scm4 <- confusionMatrix(svm4,  mode = "prec_recall")
scm5 <- confusionMatrix(svm5,  mode = "prec_recall")
scm6 <- confusionMatrix(svm6,  mode = "prec_recall")

# save confusion matrices
# saveRDS(scm1, "data/scm1.rds")
# saveRDS(scm2, "data/scm2.rds")
# saveRDS(scm3, "data/scm3.rds")
# saveRDS(scm4, "data/scm4.rds")
# saveRDS(scm5, "data/scm5.rds")
# saveRDS(scm6, "data/scm6.rds")
```

```{r}
# combined hyperparameters results table
results_r <- results_rf %>%
  group_by(Model) %>%
  summarise("Accuracy" = round(mean(Accuracy), 4), "Kappa" = round(mean(Kappa), 4),
            "mtry" = mean(mtry)) %>%
  rename("Random Forest Model" = Model)

results_s <- results_svm %>%
  group_by(Model) %>%
  summarise("Accuracy" = round(mean(Accuracy), 4), "Kappa" = round(mean(Kappa), 4)) %>%
  rename("SVM Model Kernel" = Model)

# save results tables
# write.csv(results_r,'data/results_r.csv', row.names = F)
# write.csv(results_s,'data/results_s.csv', row.names = F)
```

```{r}
# test set results for overall prediction
test_results <- data.frame(Class = test$Cmmn_Nm)
test_results$RF <- predict(rf_random3, test)
test_results$SVM <- predict(svm2, test)

test_results_grouped <- data.frame(Class = test_grouped$Cmmn_Nm)
test_results_grouped$RF <- predict(rf2_grouped, test_grouped)
test_results_grouped$SVM <- predict(svm6, test_grouped)

test_results %>%
  summarise("RF Accuracy" = sum(Class == RF)/nrow(test_results), 
            "SVM Accuracy" = sum(Class == SVM)/nrow(test_results))
test_results_grouped %>%
  summarise("RF Accuracy" = sum(Class == RF)/nrow(test_results), 
            "SVM Accuracy" = sum(Class == SVM)/nrow(test_results))

# test set results for predicting Western Redcedar
test_results_redceder <- test_results %>%
  filter(Class %in% "Western Redcedar")
test_grouped_redceder <- test_results_grouped %>%
  filter(Class %in% "Western Redcedar")

full <- test_results_redceder %>%
  summarise(rf_accuracy = sum(Class == RF)/nrow(test_results_redceder), 
            svm_accuracy = sum(Class == SVM)/nrow(test_results_redceder))

grouped <- test_grouped_redceder %>%
  summarise(rf_accuracy = sum(Class == RF)/nrow(test_grouped_redceder), 
            svm_accuracy = sum(Class == SVM)/nrow(test_grouped_redceder))

# precision and recall for Western Redcedar
cm_test <- confusionMatrix(test_results$RF, test_results$Class)
cm_test_grouped <- confusionMatrix(test_results_grouped$RF, test_results_grouped$Class)
```

```{r}
# overall polygons results (7 class radial svm, 5 class 8 predictor rf)

# join test results to full test data (with polygon info)
test_dat <- cbind(test_full, SVM = test_results$SVM) 
test_dat_grouped <- cbind(test_full_grouped, RF = test_results_grouped$RF) 

# "correct" prediction if more than half pixels in polygon are correctly predicted

# rf polygon results for 5 class prediction
poly_test_rf <- test_dat_grouped %>%
  group_by(ID) %>%
  count(ID, same_rf = (RF %in% Cmmn_Nm), total = n()) %>%
  pivot_wider(names_from = same_rf, values_from = n)

poly_test_rf[is.na(poly_test_rf)] <- 0 # replace na with 0

poly_test_rf <- poly_test_rf %>%
  mutate(Result = case_when(`TRUE` > `FALSE` ~ "Correct",
                                   `TRUE` <= `FALSE` ~ "Incorrect"))

poly_test_rf %>%
  group_by(Result) %>%
  count(Result)

# svm polygon results for 7 class prediction
poly_test_svm <- test_dat %>%
  group_by(ID) %>%
  count(ID, same_svm = (SVM == Cmmn_Nm), total = n()) %>%
  pivot_wider(names_from = same_svm, values_from = n)

poly_test_svm[is.na(poly_test_svm)] <- 0 # replace na with 0

poly_test_svm <- poly_test_svm %>%
  mutate(Result = case_when(`TRUE` > `FALSE` ~ "Correct",
                                   `TRUE` <= `FALSE` ~ "Incorrect"))

poly_test_svm %>%
  group_by(Result) %>%
  count(Result)

# save results
# write.csv(test_results,'data/test_results.csv', row.names = F)
# write.csv(test_results_grouped,'data/test_results_grouped.csv', row.names = F)
# write.csv(poly_test_rf,'data/poly_test_rf.csv', row.names = F)
# write.csv(poly_test_svm,'data/poly_test_svm.csv', row.names = F)

# save best models
# saveRDS(rf_random3, "data/rf_model.rds")
# saveRDS(rf2_grouped, "data/rf_model_grouped.rds")
```

Plot results
```{r}
# # polygon data
# poly_join_reprojected <- readRDS("data/poly_join_reprojected.rds")
# 
# # combine with latitude info from poly_reprojected in work/geographic_join.Rmd
# poly_join_reprojected@data <- poly_join_reprojected@data %>%
#   left_join(poly_test_vector, by = c("id" = "ID"))
# 
# # make key to match projected data with vector using spCbind
# o <- match(poly_join_reprojected@data$id, poly_test_vector$ID)
# results_vector <- poly_test_vector[o,]
# spCbind(obj = poly_join_reprojected, x = results_vector)
# 
# # make dataframe for ggplot
# results_pts <- fortify(poly_join_reprojected, region = "id")
# results_df <- merge(results_pts, poly_join_reprojected@data, by = "id")
# 
# # initial ggplot
# ggplot(results_df, aes(x = long, y = lat, group = id, color = result)) + 
#   geom_polygon(size = 2) +
#   scale_fill_brewer() + theme_minimal() +
#   theme(axis.title=element_blank(),
#         axis.text=element_blank(),
#         axis.ticks=element_blank(), 
#         panel.grid.major = element_blank(),
#         panel.grid.minor = element_blank(),
#         legend.position = "none")
# 
# # add city outline
# mult_county <- county_subdivisions('Oregon', 'Multnomah')
# 
# poly_sf <- st_as_sf(poly_join_reprojected)
# 
# ggplot(data = poly_sf, aes(color = result)) + 
#   geom_sf(size = 2) +
#   scale_color_viridis_d(direction = -1)
```

